{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 495746 entries, 0 to 495745\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   INCIDENT_ID             495746 non-null  int64  \n",
      " 1   OFFENSE_ID              495746 non-null  int64  \n",
      " 2   OFFENSE_CODE            495746 non-null  int64  \n",
      " 3   OFFENSE_CODE_EXTENSION  495746 non-null  int64  \n",
      " 4   OFFENSE_TYPE_ID         495746 non-null  object \n",
      " 5   OFFENSE_CATEGORY_ID     495746 non-null  object \n",
      " 6   FIRST_OCCURRENCE_DATE   495746 non-null  object \n",
      " 7   LAST_OCCURRENCE_DATE    159333 non-null  object \n",
      " 8   REPORTED_DATE           495746 non-null  object \n",
      " 9   INCIDENT_ADDRESS        449064 non-null  object \n",
      " 10  GEO_X                   491453 non-null  float64\n",
      " 11  GEO_Y                   491453 non-null  float64\n",
      " 12  GEO_LON                 491453 non-null  float64\n",
      " 13  GEO_LAT                 491453 non-null  float64\n",
      " 14  DISTRICT_ID             495746 non-null  int64  \n",
      " 15  PRECINCT_ID             495746 non-null  int64  \n",
      " 16  NEIGHBORHOOD_ID         495746 non-null  object \n",
      " 17  IS_CRIME                495746 non-null  int64  \n",
      " 18  IS_TRAFFIC              495746 non-null  int64  \n",
      "dtypes: float64(4), int64(8), object(7)\n",
      "memory usage: 71.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/Raw/crime.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAST_OCCURRENCE_DATE      336413\n",
       "INCIDENT_ADDRESS           46682\n",
       "GEO_LAT                     4293\n",
       "GEO_LON                     4293\n",
       "GEO_Y                       4293\n",
       "GEO_X                       4293\n",
       "FIRST_OCCURRENCE_DATE          0\n",
       "OFFENSE_ID                     0\n",
       "OFFENSE_CODE                   0\n",
       "OFFENSE_CODE_EXTENSION         0\n",
       "OFFENSE_TYPE_ID                0\n",
       "OFFENSE_CATEGORY_ID            0\n",
       "IS_TRAFFIC                     0\n",
       "REPORTED_DATE                  0\n",
       "IS_CRIME                       0\n",
       "DISTRICT_ID                    0\n",
       "PRECINCT_ID                    0\n",
       "NEIGHBORHOOD_ID                0\n",
       "INCIDENT_ID                    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crime_cleaner():\n",
    "    \n",
    "    # importing the 'CRIME' dataset\n",
    "    data_path = \"../data/Raw/crime.csv\"\n",
    "\n",
    "    # columns from the dataset to be used in the analysis\n",
    "    crime_df_columns = ['INCIDENT_ID', 'OFFENSE_ID', 'OFFENSE_CODE', 'OFFENSE_CODE_EXTENSION',\n",
    "                        'OFFENSE_TYPE_ID', 'OFFENSE_CATEGORY_ID', 'FIRST_OCCURRENCE_DATE','REPORTED_DATE',\n",
    "                        'DISTRICT_ID', 'PRECINCT_ID', 'NEIGHBORHOOD_ID', 'IS_CRIME', 'IS_TRAFFIC']\n",
    "\n",
    "    # reading the data into a crime_df\n",
    "    crime_df = pd.read_csv(data_path, \n",
    "                     usecols=crime_df_columns, \n",
    "                     dtype={\n",
    "                         'OFFENSE_CODE': 'category',\n",
    "                         'OFFENSE_TYPE_ID': 'category',\n",
    "                         'OFFENSE_CATEGORY_ID': 'category',\n",
    "                         'NEIGHBORHOOD_ID': 'category',\n",
    "                         'DISTRICT_ID': 'category',\n",
    "                         'PRECINCT_ID': 'category',\n",
    "                         'IS_CRIME': 'bool',\n",
    "                         'IS_TRAFFIC': 'bool'},\n",
    "                     low_memory= False)\n",
    "\n",
    "    # uppercasing text \n",
    "    crime_df['NEIGHBORHOOD_ID'] = crime_df['NEIGHBORHOOD_ID'].str.upper()\n",
    "    crime_df['OFFENSE_TYPE_ID'] = crime_df['OFFENSE_TYPE_ID'].str.upper()\n",
    "    crime_df['OFFENSE_CATEGORY_ID'] = crime_df['OFFENSE_CATEGORY_ID'].str.upper()\n",
    "\n",
    "    # saving CRIME INFO to 'crime_info.csv' \n",
    "    crime_df.to_csv('../data/Clean/crime_info.csv', index=False)\n",
    "    \n",
    "    print('CRIME DATA CLEANED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_cleaner():\n",
    "    \n",
    "    # importing the 'CRIME' dataset\n",
    "    data_path = \"../data/Raw/crime.csv\"\n",
    "    \n",
    "    # columns from the dataset that provide geolocation information\n",
    "    geo_fields = ['OFFENSE_ID', 'NEIGHBORHOOD_ID', 'INCIDENT_ADDRESS','GEO_X', \n",
    "                  'GEO_Y', 'GEO_LON', 'GEO_LAT']\n",
    "\n",
    "    # saves the geolocation data separately\n",
    "    geo_df = pd.read_csv(data_path,usecols=geo_fields,\n",
    "                        dtype={'NEIGHBORHOOD_ID': 'category'},\n",
    "                         low_memory=False)\n",
    "\n",
    "    # uppercasing text\n",
    "    geo_df['NEIGHBORHOOD_ID'] = geo_df['NEIGHBORHOOD_ID'].str.upper()\n",
    "\n",
    "    # saving geo info to 'geo_info.csv' \n",
    "    geo_df.to_csv('../data/Clean/geo_info.csv', index=False)\n",
    "    \n",
    "    print('GEO DATA CLEANED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offense Codes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offense_cleaner():\n",
    "\n",
    "    # importing the 'offense' dataset\n",
    "    data_path = \"../data/Raw/offense_codes.csv\"\n",
    "\n",
    "    # reading the data into a offense_df\n",
    "    offense_df = pd.read_csv(data_path, \n",
    "                     dtype={\n",
    "                         'OFFENSE_CODE': 'category',\n",
    "                         'OFFENSE_CODE_EXTENSION': 'category',\n",
    "                         'OFFENSE_TYPE_ID': 'category',\n",
    "                         'OFFENSE_TYPE_NAME': 'category',\n",
    "                         'OFFENSE_CATEGORY_ID': 'category',\n",
    "                         'OFFENSE_CATEGORY_NAME': 'category',\n",
    "                         'IS_CRIME': 'bool',\n",
    "                         'IS_TRAFFIC': 'bool'})\n",
    "\n",
    "    # uppercasing text\n",
    "    offense_df['OFFENSE_TYPE_ID'] = offense_df['OFFENSE_TYPE_ID'].str.upper()\n",
    "    offense_df['OFFENSE_TYPE_NAME'] = offense_df['OFFENSE_TYPE_NAME'].str.upper()\n",
    "    offense_df['OFFENSE_CATEGORY_ID'] = offense_df['OFFENSE_CATEGORY_ID'].str.upper()\n",
    "    offense_df['OFFENSE_CATEGORY_NAME'] = offense_df['OFFENSE_CATEGORY_NAME'].str.upper()\n",
    "\n",
    "    # saving offense info to 'offense_info.csv' \n",
    "    offense_df.to_csv('../data/Clean/offense_info.csv', index=False)\n",
    "    \n",
    "    print('OFFENSE DATA CLEANED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIME DATA CLEANED\n",
      "GEO DATA CLEANED\n",
      "OFFENSE DATA CLEANED\n"
     ]
    }
   ],
   "source": [
    "crime_cleaner()\n",
    "geo_cleaner()\n",
    "offense_cleaner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
